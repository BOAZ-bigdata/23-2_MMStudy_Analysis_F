{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH8. 성능 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실습해볼 task : Sentence Positive/Negative Classificationn using CNN(CNN 기반 문장의 긍부정 분류)\n",
    "- 실습 순서\n",
    "    - [참고자료](https://github.com/graykode/nlp-tutorial/blob/master/2-1.TextCNN/TextCNN.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 필요한 라이브러리 & 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "from models import text_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CH9장 내용 기반 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터(일종의 corpus) load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "            \"i love you\", \n",
    "            \"he loves me\", \n",
    "            \"she likes baseball\", \n",
    "            \"i hate you\", \n",
    "            \"sorry for that\", \n",
    "            \"this is awful\"\n",
    "]\n",
    "labels = [1, 1, 1, 0, 0, 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenization 진행\n",
    "    - 문장을 단어 단위로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball',\n",
       " 'hate',\n",
       " 'you',\n",
       " 'this',\n",
       " 'sorry',\n",
       " 'that',\n",
       " 'loves',\n",
       " 'i',\n",
       " 'he',\n",
       " 'for',\n",
       " 'is',\n",
       " 'she',\n",
       " 'awful',\n",
       " 'love',\n",
       " 'likes',\n",
       " 'me']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \" \".join(corpus).split()\n",
    "words = list(set(words))\n",
    "words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰에 정수 매핑하는 딕셔너리 만들기\n",
    "    - 단어 데이터를 모델이 이해할 수 있는 정수로 이루어진 벡터로 바꾸기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseball': 0,\n",
       " 'hate': 1,\n",
       " 'you': 2,\n",
       " 'this': 3,\n",
       " 'sorry': 4,\n",
       " 'that': 5,\n",
       " 'loves': 6,\n",
       " 'i': 7,\n",
       " 'he': 8,\n",
       " 'for': 9,\n",
       " 'is': 10,\n",
       " 'she': 11,\n",
       " 'awful': 12,\n",
       " 'love': 13,\n",
       " 'likes': 14,\n",
       " 'me': 15}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {w: i for i, w in enumerate(words)}\n",
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input 데이터 텐서화\n",
    "    - 문장 -> 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 데이터 shape: torch.Size([6, 3])\n",
      "target 데이터 shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.LongTensor([np.asarray([word_dict[n] for n in sentence.split()]) for sentence in corpus])\n",
    "targets = torch.LongTensor([out for out in labels]) \n",
    "print(f\"input 데이터 shape: {inputs.size()}\")\n",
    "print(f\"target 데이터 shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 성능 최적화 이용 학습\n",
    "- 하이퍼파라미터 성능 최적화\n",
    "    - 배치 정규화\n",
    "    - 드롭아웃\n",
    "    - 조기 종료\n",
    "    - 모델 파리미터 튜닝\n",
    "- 성능 최적화\n",
    "    - 앙상블 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 3 \n",
    "filter_sizes = [2, 2, 2] \n",
    "vocab_size = len(word_dict)\n",
    "embedding_size = 2 \n",
    "sequence_length = 3 \n",
    "num_classes = 2 \n",
    "model = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.689684\n",
      "Epoch: 0002 cost = 0.686636\n",
      "Epoch: 0003 cost = 0.683598\n",
      "Epoch: 0004 cost = 0.680571\n",
      "Epoch: 0005 cost = 0.677553\n",
      "Epoch: 0006 cost = 0.674546\n",
      "Epoch: 0007 cost = 0.671548\n",
      "Epoch: 0008 cost = 0.668557\n",
      "Epoch: 0009 cost = 0.665572\n",
      "Epoch: 0010 cost = 0.662590\n",
      "Epoch: 0011 cost = 0.659609\n",
      "Epoch: 0012 cost = 0.656628\n",
      "Epoch: 0013 cost = 0.653645\n",
      "Epoch: 0014 cost = 0.650659\n",
      "Epoch: 0015 cost = 0.647669\n",
      "Epoch: 0016 cost = 0.644673\n",
      "Epoch: 0017 cost = 0.641670\n",
      "Epoch: 0018 cost = 0.638661\n",
      "Epoch: 0019 cost = 0.635644\n",
      "Epoch: 0020 cost = 0.632619\n",
      "Epoch: 0021 cost = 0.629586\n",
      "Epoch: 0022 cost = 0.626543\n",
      "Epoch: 0023 cost = 0.623492\n",
      "Epoch: 0024 cost = 0.620431\n",
      "Epoch: 0025 cost = 0.617360\n",
      "Epoch: 0026 cost = 0.614280\n",
      "Epoch: 0027 cost = 0.611218\n",
      "Epoch: 0028 cost = 0.608128\n",
      "Epoch: 0029 cost = 0.605034\n",
      "Epoch: 0030 cost = 0.601938\n",
      "Epoch: 0031 cost = 0.598830\n",
      "Epoch: 0032 cost = 0.595710\n",
      "Epoch: 0033 cost = 0.592578\n",
      "Epoch: 0034 cost = 0.589436\n",
      "Epoch: 0035 cost = 0.586282\n",
      "Epoch: 0036 cost = 0.583138\n",
      "Epoch: 0037 cost = 0.580182\n",
      "Epoch: 0038 cost = 0.577206\n",
      "Epoch: 0039 cost = 0.574206\n",
      "Epoch: 0040 cost = 0.571184\n",
      "Epoch: 0041 cost = 0.568168\n",
      "Epoch: 0042 cost = 0.565136\n",
      "Epoch: 0043 cost = 0.562091\n",
      "Epoch: 0044 cost = 0.559033\n",
      "Epoch: 0045 cost = 0.555968\n",
      "Epoch: 0046 cost = 0.552887\n",
      "Epoch: 0047 cost = 0.549798\n",
      "Epoch: 0048 cost = 0.546702\n",
      "Epoch: 0049 cost = 0.543588\n",
      "Epoch: 0050 cost = 0.540468\n",
      "Epoch: 0051 cost = 0.537337\n",
      "Epoch: 0052 cost = 0.534193\n",
      "Epoch: 0053 cost = 0.531042\n",
      "Epoch: 0054 cost = 0.527879\n",
      "Epoch: 0055 cost = 0.524707\n",
      "Epoch: 0056 cost = 0.521525\n",
      "Epoch: 0057 cost = 0.518333\n",
      "Epoch: 0058 cost = 0.515140\n",
      "Epoch: 0059 cost = 0.511924\n",
      "Epoch: 0060 cost = 0.508712\n",
      "Epoch: 0061 cost = 0.505490\n",
      "Epoch: 0062 cost = 0.502258\n",
      "Epoch: 0063 cost = 0.499017\n",
      "Epoch: 0064 cost = 0.495754\n",
      "Epoch: 0065 cost = 0.492403\n",
      "Epoch: 0066 cost = 0.489035\n",
      "Epoch: 0067 cost = 0.485674\n",
      "Epoch: 0068 cost = 0.482322\n",
      "Epoch: 0069 cost = 0.478939\n",
      "Epoch: 0070 cost = 0.475543\n",
      "Epoch: 0071 cost = 0.472119\n",
      "Epoch: 0072 cost = 0.468696\n",
      "Epoch: 0073 cost = 0.465288\n",
      "Epoch: 0074 cost = 0.461884\n",
      "Epoch: 0075 cost = 0.458472\n",
      "Epoch: 0076 cost = 0.455054\n",
      "Epoch: 0077 cost = 0.451630\n",
      "Epoch: 0078 cost = 0.448202\n",
      "Epoch: 0079 cost = 0.444770\n",
      "Epoch: 0080 cost = 0.441395\n",
      "Epoch: 0081 cost = 0.438048\n",
      "Epoch: 0082 cost = 0.434701\n",
      "Epoch: 0083 cost = 0.431361\n",
      "Epoch: 0084 cost = 0.428014\n",
      "Epoch: 0085 cost = 0.424669\n",
      "Epoch: 0086 cost = 0.421324\n",
      "Epoch: 0087 cost = 0.417979\n",
      "Epoch: 0088 cost = 0.414635\n",
      "Epoch: 0089 cost = 0.411292\n",
      "Epoch: 0090 cost = 0.407953\n",
      "Epoch: 0091 cost = 0.404636\n",
      "Epoch: 0092 cost = 0.401306\n",
      "Epoch: 0093 cost = 0.397973\n",
      "Epoch: 0094 cost = 0.394674\n",
      "Epoch: 0095 cost = 0.391468\n",
      "Epoch: 0096 cost = 0.388279\n",
      "Epoch: 0097 cost = 0.385114\n",
      "Epoch: 0098 cost = 0.381921\n",
      "Epoch: 0099 cost = 0.378706\n",
      "Epoch: 0100 cost = 0.375482\n",
      "he hate you is Bad Mean...\n"
     ]
    }
   ],
   "source": [
    "train_model(model,inputs,targets,100)\n",
    "test_text = 'he hate you'\n",
    "tests = [np.asarray([word_dict[n] for n in test_text.split()])]\n",
    "test_batch = torch.LongTensor(tests)\n",
    "\n",
    "# Predict\n",
    "predict = model(test_batch).data.max(1, keepdim=True)[1]\n",
    "if predict[0][0] == 0:\n",
    "    print(test_text,\"is Bad Mean...\")\n",
    "else:\n",
    "    print(test_text,\"is Good Mean!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23-2_MMStudy_Analysis_F-O1JOBGQa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
