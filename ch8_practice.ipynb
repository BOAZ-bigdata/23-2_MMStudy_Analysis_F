{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH8. 성능 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실습해볼 task : Sentence Positive/Negative Classificationn using CNN(CNN 기반 문장의 긍부정 분류)\n",
    "- 실습 순서\n",
    "    - [참고자료](https://github.com/graykode/nlp-tutorial/blob/master/2-1.TextCNN/TextCNN.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 필요한 라이브러리 & 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from models import text_cnn\n",
    "from train import train_model\n",
    "from test import test_model\n",
    "from train import train_model_with_early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CH9장 내용 기반 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터(일종의 corpus) load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "            \"i love you\", \n",
    "            \"he loves me\", \n",
    "            \"she likes baseball\", \n",
    "            \"i hate you\", \n",
    "            \"sorry for that\", \n",
    "            \"this is awful\"\n",
    "]\n",
    "labels = [1, 1, 1, 0, 0, 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenization 진행\n",
    "    - 문장을 단어 단위로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate',\n",
       " 'he',\n",
       " 'baseball',\n",
       " 'love',\n",
       " 'me',\n",
       " 'you',\n",
       " 'loves',\n",
       " 'for',\n",
       " 'this',\n",
       " 'is',\n",
       " 'awful',\n",
       " 'i',\n",
       " 'likes',\n",
       " 'that',\n",
       " 'sorry',\n",
       " 'she']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \" \".join(corpus).split()\n",
    "words = list(set(words))\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰에 정수 매핑하는 딕셔너리 만들기\n",
    "    - 단어 데이터를 모델이 이해할 수 있는 정수로 이루어진 벡터로 바꾸기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate': 0,\n",
       " 'he': 1,\n",
       " 'baseball': 2,\n",
       " 'love': 3,\n",
       " 'me': 4,\n",
       " 'you': 5,\n",
       " 'loves': 6,\n",
       " 'for': 7,\n",
       " 'this': 8,\n",
       " 'is': 9,\n",
       " 'awful': 10,\n",
       " 'i': 11,\n",
       " 'likes': 12,\n",
       " 'that': 13,\n",
       " 'sorry': 14,\n",
       " 'she': 15}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {w: i for i, w in enumerate(words)}\n",
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input 데이터 텐서화\n",
    "    - 문장 -> 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 데이터 shape: torch.Size([6, 3])\n",
      "target 데이터 shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "sentence_arrays = [np.asarray([word_dict[n] for n in sentence.split()]) for sentence in corpus]\n",
    "inputs = torch.LongTensor(sentence_arrays)\n",
    "label_array = np.asarray(labels)\n",
    "targets = torch.LongTensor(label_array)\n",
    "print(f\"input 데이터 shape: {inputs.size()}\")\n",
    "print(f\"target 데이터 shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Mapping: i love you\n",
      "After Mapping: tensor([11,  3,  5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before Mapping: {corpus[0]}\")\n",
    "print(f\"After Mapping: {inputs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 성능 최적화 이용 학습\n",
    "- Batch Normalization\n",
    "- Drop Out\n",
    "- Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train & test vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_filters = 3 \n",
    "filter_sizes = [2, 2, 2] \n",
    "vocab_size = len(word_dict)\n",
    "embedding_size = 2 \n",
    "sequence_length = 3 \n",
    "num_classes = 2 \n",
    "\n",
    "model = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes\n",
    ")\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.826689\n",
      "Epoch: 0002 cost = 0.822922\n",
      "Epoch: 0003 cost = 0.819225\n",
      "Epoch: 0004 cost = 0.815597\n",
      "Epoch: 0005 cost = 0.812040\n",
      "Epoch: 0006 cost = 0.808555\n",
      "Epoch: 0007 cost = 0.805143\n",
      "Epoch: 0008 cost = 0.801804\n",
      "Epoch: 0009 cost = 0.798730\n",
      "Epoch: 0010 cost = 0.795727\n",
      "Epoch: 0011 cost = 0.792770\n",
      "Epoch: 0012 cost = 0.789866\n",
      "Epoch: 0013 cost = 0.787021\n",
      "Epoch: 0014 cost = 0.784236\n",
      "Epoch: 0015 cost = 0.781511\n",
      "Epoch: 0016 cost = 0.778848\n",
      "Epoch: 0017 cost = 0.776245\n",
      "Epoch: 0018 cost = 0.773702\n",
      "Epoch: 0019 cost = 0.771216\n",
      "Epoch: 0020 cost = 0.768786\n",
      "Epoch: 0021 cost = 0.766410\n",
      "Epoch: 0022 cost = 0.764085\n",
      "Epoch: 0023 cost = 0.761810\n",
      "Epoch: 0024 cost = 0.759582\n",
      "Epoch: 0025 cost = 0.757399\n",
      "Epoch: 0026 cost = 0.755259\n",
      "Epoch: 0027 cost = 0.753160\n",
      "Epoch: 0028 cost = 0.751117\n",
      "Epoch: 0029 cost = 0.749130\n",
      "Epoch: 0030 cost = 0.747160\n",
      "Epoch: 0031 cost = 0.745208\n",
      "Epoch: 0032 cost = 0.743294\n",
      "Epoch: 0033 cost = 0.741432\n",
      "Epoch: 0034 cost = 0.739599\n",
      "Epoch: 0035 cost = 0.737793\n",
      "Epoch: 0036 cost = 0.736015\n",
      "Epoch: 0037 cost = 0.734263\n",
      "Epoch: 0038 cost = 0.732537\n",
      "Epoch: 0039 cost = 0.730836\n",
      "Epoch: 0040 cost = 0.729161\n",
      "Epoch: 0041 cost = 0.727509\n",
      "Epoch: 0042 cost = 0.725904\n",
      "Epoch: 0043 cost = 0.724309\n",
      "Epoch: 0044 cost = 0.722719\n",
      "Epoch: 0045 cost = 0.721170\n",
      "Epoch: 0046 cost = 0.719646\n",
      "Epoch: 0047 cost = 0.718139\n",
      "Epoch: 0048 cost = 0.716649\n",
      "Epoch: 0049 cost = 0.715176\n",
      "Epoch: 0050 cost = 0.713719\n",
      "Epoch: 0051 cost = 0.712277\n",
      "Epoch: 0052 cost = 0.710849\n",
      "Epoch: 0053 cost = 0.709435\n",
      "Epoch: 0054 cost = 0.708034\n",
      "Epoch: 0055 cost = 0.706652\n",
      "Epoch: 0056 cost = 0.705286\n",
      "Epoch: 0057 cost = 0.703924\n",
      "Epoch: 0058 cost = 0.702582\n",
      "Epoch: 0059 cost = 0.701248\n",
      "Epoch: 0060 cost = 0.699922\n",
      "Epoch: 0061 cost = 0.698603\n",
      "Epoch: 0062 cost = 0.697292\n",
      "Epoch: 0063 cost = 0.696006\n",
      "Epoch: 0064 cost = 0.694709\n",
      "Epoch: 0065 cost = 0.693419\n",
      "Epoch: 0066 cost = 0.692144\n",
      "Epoch: 0067 cost = 0.690873\n",
      "Epoch: 0068 cost = 0.689605\n",
      "Epoch: 0069 cost = 0.688340\n",
      "Epoch: 0070 cost = 0.687079\n",
      "Epoch: 0071 cost = 0.685819\n",
      "Epoch: 0072 cost = 0.684562\n",
      "Epoch: 0073 cost = 0.683327\n",
      "Epoch: 0074 cost = 0.682078\n",
      "Epoch: 0075 cost = 0.680818\n",
      "Epoch: 0076 cost = 0.679563\n",
      "Epoch: 0077 cost = 0.678253\n",
      "Epoch: 0078 cost = 0.676913\n",
      "Epoch: 0079 cost = 0.675553\n",
      "Epoch: 0080 cost = 0.674175\n",
      "Epoch: 0081 cost = 0.672782\n",
      "Epoch: 0082 cost = 0.671392\n",
      "Epoch: 0083 cost = 0.669975\n",
      "Epoch: 0084 cost = 0.668552\n",
      "Epoch: 0085 cost = 0.667127\n",
      "Epoch: 0086 cost = 0.665694\n",
      "Epoch: 0087 cost = 0.664252\n",
      "Epoch: 0088 cost = 0.662803\n",
      "Epoch: 0089 cost = 0.661348\n",
      "Epoch: 0090 cost = 0.659886\n",
      "Epoch: 0091 cost = 0.658418\n",
      "Epoch: 0092 cost = 0.656944\n",
      "Epoch: 0093 cost = 0.655486\n",
      "Epoch: 0094 cost = 0.654004\n",
      "Epoch: 0095 cost = 0.652506\n",
      "Epoch: 0096 cost = 0.651020\n",
      "Epoch: 0097 cost = 0.649528\n",
      "Epoch: 0098 cost = 0.648029\n",
      "Epoch: 0099 cost = 0.646524\n",
      "Epoch: 0100 cost = 0.645013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_model(model,inputs,targets,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he loves you is Good Mean!!\n"
     ]
    }
   ],
   "source": [
    "test_text = 'he loves you'\n",
    "tests = [np.asarray([word_dict[n] for n in test_text.split()])]\n",
    "test_input = torch.LongTensor(tests)\n",
    "prediction = test_model(model,test_input)\n",
    "\n",
    "if prediction == 0:\n",
    "    print(test_text,\"is Bad Mean...\")\n",
    "else:\n",
    "    print(test_text,\"is Good Mean!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What is Batch Normalization?\n",
    "- `normalization`\n",
    "    - 정규화 : 데이터 범위를 사용자가 원하는 범위로 제한하는 것\n",
    "        - feature scaling으로도 불림\n",
    "    - 방법\n",
    "        - [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train vanilla model + batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       "  (batch_norm_list): ModuleList(\n",
       "    (0-2): 3 x BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batchnormalized = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes,is_batch_normalize=True\n",
    ")\n",
    "model_batchnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.620625\n",
      "Epoch: 0002 cost = 0.613888\n",
      "Epoch: 0003 cost = 0.607239\n",
      "Epoch: 0004 cost = 0.600677\n",
      "Epoch: 0005 cost = 0.594204\n",
      "Epoch: 0006 cost = 0.587821\n",
      "Epoch: 0007 cost = 0.581639\n",
      "Epoch: 0008 cost = 0.575679\n",
      "Epoch: 0009 cost = 0.569792\n",
      "Epoch: 0010 cost = 0.563975\n",
      "Epoch: 0011 cost = 0.558229\n",
      "Epoch: 0012 cost = 0.552551\n",
      "Epoch: 0013 cost = 0.546994\n",
      "Epoch: 0014 cost = 0.541419\n",
      "Epoch: 0015 cost = 0.535926\n",
      "Epoch: 0016 cost = 0.530508\n",
      "Epoch: 0017 cost = 0.525145\n",
      "Epoch: 0018 cost = 0.519833\n",
      "Epoch: 0019 cost = 0.514572\n",
      "Epoch: 0020 cost = 0.509361\n",
      "Epoch: 0021 cost = 0.504197\n",
      "Epoch: 0022 cost = 0.499081\n",
      "Epoch: 0023 cost = 0.494011\n",
      "Epoch: 0024 cost = 0.488986\n",
      "Epoch: 0025 cost = 0.484007\n",
      "Epoch: 0026 cost = 0.479072\n",
      "Epoch: 0027 cost = 0.474181\n",
      "Epoch: 0028 cost = 0.469333\n",
      "Epoch: 0029 cost = 0.464530\n",
      "Epoch: 0030 cost = 0.459768\n",
      "Epoch: 0031 cost = 0.455047\n",
      "Epoch: 0032 cost = 0.450363\n",
      "Epoch: 0033 cost = 0.445718\n",
      "Epoch: 0034 cost = 0.441112\n",
      "Epoch: 0035 cost = 0.436544\n",
      "Epoch: 0036 cost = 0.432015\n",
      "Epoch: 0037 cost = 0.427523\n",
      "Epoch: 0038 cost = 0.423068\n",
      "Epoch: 0039 cost = 0.418650\n",
      "Epoch: 0040 cost = 0.414268\n",
      "Epoch: 0041 cost = 0.409923\n",
      "Epoch: 0042 cost = 0.405612\n",
      "Epoch: 0043 cost = 0.401371\n",
      "Epoch: 0044 cost = 0.397166\n",
      "Epoch: 0045 cost = 0.392996\n",
      "Epoch: 0046 cost = 0.388861\n",
      "Epoch: 0047 cost = 0.384761\n",
      "Epoch: 0048 cost = 0.380694\n",
      "Epoch: 0049 cost = 0.376661\n",
      "Epoch: 0050 cost = 0.372687\n",
      "Epoch: 0051 cost = 0.368736\n",
      "Epoch: 0052 cost = 0.364801\n",
      "Epoch: 0053 cost = 0.360893\n",
      "Epoch: 0054 cost = 0.357013\n",
      "Epoch: 0055 cost = 0.353160\n",
      "Epoch: 0056 cost = 0.349334\n",
      "Epoch: 0057 cost = 0.345535\n",
      "Epoch: 0058 cost = 0.341762\n",
      "Epoch: 0059 cost = 0.338016\n",
      "Epoch: 0060 cost = 0.334296\n",
      "Epoch: 0061 cost = 0.330566\n",
      "Epoch: 0062 cost = 0.326844\n",
      "Epoch: 0063 cost = 0.323140\n",
      "Epoch: 0064 cost = 0.319456\n",
      "Epoch: 0065 cost = 0.315793\n",
      "Epoch: 0066 cost = 0.312151\n",
      "Epoch: 0067 cost = 0.308531\n",
      "Epoch: 0068 cost = 0.304934\n",
      "Epoch: 0069 cost = 0.301360\n",
      "Epoch: 0070 cost = 0.297809\n",
      "Epoch: 0071 cost = 0.294283\n",
      "Epoch: 0072 cost = 0.290861\n",
      "Epoch: 0073 cost = 0.287458\n",
      "Epoch: 0074 cost = 0.284076\n",
      "Epoch: 0075 cost = 0.280713\n",
      "Epoch: 0076 cost = 0.277371\n",
      "Epoch: 0077 cost = 0.274047\n",
      "Epoch: 0078 cost = 0.270730\n",
      "Epoch: 0079 cost = 0.267406\n",
      "Epoch: 0080 cost = 0.264098\n",
      "Epoch: 0081 cost = 0.260795\n",
      "Epoch: 0082 cost = 0.257501\n",
      "Epoch: 0083 cost = 0.254217\n",
      "Epoch: 0084 cost = 0.250947\n",
      "Epoch: 0085 cost = 0.247719\n",
      "Epoch: 0086 cost = 0.244510\n",
      "Epoch: 0087 cost = 0.241316\n",
      "Epoch: 0088 cost = 0.238138\n",
      "Epoch: 0089 cost = 0.234976\n",
      "Epoch: 0090 cost = 0.231830\n",
      "Epoch: 0091 cost = 0.228702\n",
      "Epoch: 0092 cost = 0.225590\n",
      "Epoch: 0093 cost = 0.222497\n",
      "Epoch: 0094 cost = 0.219434\n",
      "Epoch: 0095 cost = 0.216395\n",
      "Epoch: 0096 cost = 0.213370\n",
      "Epoch: 0097 cost = 0.210360\n",
      "Epoch: 0098 cost = 0.207366\n",
      "Epoch: 0099 cost = 0.204413\n",
      "Epoch: 0100 cost = 0.201506\n"
     ]
    }
   ],
   "source": [
    "train_model(model_batchnormalized,inputs,targets,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 What is Drop Out?\n",
    "- drop out \n",
    "    - 드롭아웃 : 학습 시 , 일정 비율의 뉴런만 사용하고 나머지 뉴런에 해당하는 가중치는 업데이트 하지 않는 방법\n",
    "        - 매 단계마다 사용하지 않는 뉴런을 바꾼다.\n",
    "    - 방법 \n",
    "        - [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train & test vanilla model + dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes, dropout_prob = 0.5\n",
    ")\n",
    "model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.717489\n",
      "Epoch: 0002 cost = 0.658339\n",
      "Epoch: 0003 cost = 0.755907\n",
      "Epoch: 0004 cost = 0.526005\n",
      "Epoch: 0005 cost = 0.750599\n",
      "Epoch: 0006 cost = 0.693036\n",
      "Epoch: 0007 cost = 0.832940\n",
      "Epoch: 0008 cost = 0.757068\n",
      "Epoch: 0009 cost = 0.563177\n",
      "Epoch: 0010 cost = 0.616058\n",
      "Epoch: 0011 cost = 0.610943\n",
      "Epoch: 0012 cost = 0.726284\n",
      "Epoch: 0013 cost = 0.643613\n",
      "Epoch: 0014 cost = 0.847523\n",
      "Epoch: 0015 cost = 0.652903\n",
      "Epoch: 0016 cost = 0.851932\n",
      "Epoch: 0017 cost = 0.639031\n",
      "Epoch: 0018 cost = 0.809204\n",
      "Epoch: 0019 cost = 0.722253\n",
      "Epoch: 0020 cost = 0.753233\n",
      "Epoch: 0021 cost = 0.613244\n",
      "Epoch: 0022 cost = 0.679789\n",
      "Epoch: 0023 cost = 0.674083\n",
      "Epoch: 0024 cost = 0.766926\n",
      "Epoch: 0025 cost = 0.780195\n",
      "Epoch: 0026 cost = 0.633055\n",
      "Epoch: 0027 cost = 0.728218\n",
      "Epoch: 0028 cost = 0.564681\n",
      "Epoch: 0029 cost = 0.590229\n",
      "Epoch: 0030 cost = 0.659879\n",
      "Epoch: 0031 cost = 0.463122\n",
      "Epoch: 0032 cost = 0.698427\n",
      "Epoch: 0033 cost = 0.853713\n",
      "Epoch: 0034 cost = 0.746249\n",
      "Epoch: 0035 cost = 0.725091\n",
      "Epoch: 0036 cost = 0.608541\n",
      "Epoch: 0037 cost = 0.630065\n",
      "Epoch: 0038 cost = 0.537746\n",
      "Epoch: 0039 cost = 0.575164\n",
      "Epoch: 0040 cost = 0.731377\n",
      "Epoch: 0041 cost = 0.549670\n",
      "Epoch: 0042 cost = 0.592010\n",
      "Epoch: 0043 cost = 0.713529\n",
      "Epoch: 0044 cost = 0.651033\n",
      "Epoch: 0045 cost = 0.511529\n",
      "Epoch: 0046 cost = 0.587504\n",
      "Epoch: 0047 cost = 0.551054\n",
      "Epoch: 0048 cost = 0.530727\n",
      "Epoch: 0049 cost = 0.508789\n",
      "Epoch: 0050 cost = 0.858620\n",
      "Epoch: 0051 cost = 0.657376\n",
      "Epoch: 0052 cost = 0.581067\n",
      "Epoch: 0053 cost = 0.657887\n",
      "Epoch: 0054 cost = 0.564996\n",
      "Epoch: 0055 cost = 0.593237\n",
      "Epoch: 0056 cost = 0.700923\n",
      "Epoch: 0057 cost = 0.664990\n",
      "Epoch: 0058 cost = 0.616028\n",
      "Epoch: 0059 cost = 0.559778\n",
      "Epoch: 0060 cost = 0.516365\n",
      "Epoch: 0061 cost = 0.661967\n",
      "Epoch: 0062 cost = 0.530612\n",
      "Epoch: 0063 cost = 0.525624\n",
      "Epoch: 0064 cost = 0.622490\n",
      "Epoch: 0065 cost = 0.546424\n",
      "Epoch: 0066 cost = 0.592973\n",
      "Epoch: 0067 cost = 0.602801\n",
      "Epoch: 0068 cost = 0.701023\n",
      "Epoch: 0069 cost = 0.655823\n",
      "Epoch: 0070 cost = 0.719944\n",
      "Epoch: 0071 cost = 0.618670\n",
      "Epoch: 0072 cost = 0.574528\n",
      "Epoch: 0073 cost = 0.561030\n",
      "Epoch: 0074 cost = 0.653713\n",
      "Epoch: 0075 cost = 0.752585\n",
      "Epoch: 0076 cost = 0.696107\n",
      "Epoch: 0077 cost = 0.535264\n",
      "Epoch: 0078 cost = 0.684876\n",
      "Epoch: 0079 cost = 0.527762\n",
      "Epoch: 0080 cost = 0.566439\n",
      "Epoch: 0081 cost = 0.621532\n",
      "Epoch: 0082 cost = 0.684660\n",
      "Epoch: 0083 cost = 0.549005\n",
      "Epoch: 0084 cost = 0.604647\n",
      "Epoch: 0085 cost = 0.536163\n",
      "Epoch: 0086 cost = 0.505392\n",
      "Epoch: 0087 cost = 0.565420\n",
      "Epoch: 0088 cost = 0.566557\n",
      "Epoch: 0089 cost = 0.499892\n",
      "Epoch: 0090 cost = 0.613296\n",
      "Epoch: 0091 cost = 0.579081\n",
      "Epoch: 0092 cost = 0.601209\n",
      "Epoch: 0093 cost = 0.509574\n",
      "Epoch: 0094 cost = 0.616908\n",
      "Epoch: 0095 cost = 0.517438\n",
      "Epoch: 0096 cost = 0.523233\n",
      "Epoch: 0097 cost = 0.556903\n",
      "Epoch: 0098 cost = 0.487090\n",
      "Epoch: 0099 cost = 0.651187\n",
      "Epoch: 0100 cost = 0.587923\n"
     ]
    }
   ],
   "source": [
    "train_model(model_dropout,inputs,targets,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 What is Early Stopping?\n",
    "- early stopping\n",
    "    - 조기 종료: 검증 데이터셋에 대한 오차가 증가하는 시점에 학습을 멈추도록 조정\n",
    "    - 방법\n",
    "        - [참고 코드](https://teddylee777.github.io/pytorch/early-stopping/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train vanilla model with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535123\n",
      "Epoch: 0002 cost = 0.627853\n",
      "Epoch: 0003 cost = 0.601587\n",
      "Epoch: 0004 cost = 0.461544\n",
      "Epoch: 0005 cost = 0.572803\n",
      "Epoch: 0006 cost = 0.635137\n",
      "Epoch: 0007 cost = 0.571512\n",
      "Epoch: 0008 cost = 0.715966\n",
      "Epoch: 0009 cost = 0.598509\n",
      "Early stopping at epoch 9 due to lack of improvement.\n"
     ]
    }
   ],
   "source": [
    "train_model_with_early_stop(model_dropout,inputs,targets,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23-2_MMStudy_Analysis_F-O1JOBGQa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
