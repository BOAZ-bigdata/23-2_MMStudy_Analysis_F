{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH8. 성능 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실습해볼 task : Sentence Positive/Negative Classificationn using CNN(CNN 기반 문장의 긍부정 분류)\n",
    "- 실습 순서\n",
    "    - [참고자료](https://github.com/graykode/nlp-tutorial/blob/master/2-1.TextCNN/TextCNN.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 필요한 라이브러리 & 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "from models import text_cnn\n",
    "from train import train_model\n",
    "from test import test_model\n",
    "from train import train_model_with_early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CH9장 내용 기반 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터(일종의 corpus) load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "            \"i love you\", \n",
    "            \"he loves me\", \n",
    "            \"she likes baseball\", \n",
    "            \"i hate you\", \n",
    "            \"sorry for that\", \n",
    "            \"this is awful\"\n",
    "]\n",
    "labels = [1, 1, 1, 0, 0, 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenization 진행\n",
    "    - 문장을 단어 단위로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'awful',\n",
       " 'i',\n",
       " 'baseball',\n",
       " 'love',\n",
       " 'hate',\n",
       " 'likes',\n",
       " 'loves',\n",
       " 'you',\n",
       " 'sorry',\n",
       " 'he',\n",
       " 'for',\n",
       " 'that',\n",
       " 'she',\n",
       " 'is',\n",
       " 'me']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \" \".join(corpus).split()\n",
    "words = list(set(words))\n",
    "words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰에 정수 매핑하는 딕셔너리 만들기\n",
    "    - 단어 데이터를 모델이 이해할 수 있는 정수로 이루어진 벡터로 바꾸기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 0,\n",
       " 'awful': 1,\n",
       " 'i': 2,\n",
       " 'baseball': 3,\n",
       " 'love': 4,\n",
       " 'hate': 5,\n",
       " 'likes': 6,\n",
       " 'loves': 7,\n",
       " 'you': 8,\n",
       " 'sorry': 9,\n",
       " 'he': 10,\n",
       " 'for': 11,\n",
       " 'that': 12,\n",
       " 'she': 13,\n",
       " 'is': 14,\n",
       " 'me': 15}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {w: i for i, w in enumerate(words)}\n",
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input 데이터 텐서화\n",
    "    - 문장 -> 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 데이터 shape: torch.Size([6, 3])\n",
      "target 데이터 shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "sentence_arrays = [np.asarray([word_dict[n] for n in sentence.split()]) for sentence in corpus]\n",
    "inputs = torch.LongTensor(sentence_arrays)\n",
    "label_array = np.asarray(labels)\n",
    "targets = torch.LongTensor(label_array)\n",
    "print(f\"input 데이터 shape: {inputs.size()}\")\n",
    "print(f\"target 데이터 shape: {targets.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 성능 최적화 이용 학습\n",
    "- Batch Normalization\n",
    "- Drop Out\n",
    "- Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train & test vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_filters = 3 \n",
    "filter_sizes = [2, 2, 2] \n",
    "vocab_size = len(word_dict)\n",
    "embedding_size = 2 \n",
    "sequence_length = 3 \n",
    "num_classes = 2 \n",
    "model = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes\n",
    ")\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.762808\n",
      "Epoch: 0002 cost = 0.759640\n",
      "Epoch: 0003 cost = 0.756512\n",
      "Epoch: 0004 cost = 0.753426\n",
      "Epoch: 0005 cost = 0.750380\n",
      "Epoch: 0006 cost = 0.747375\n",
      "Epoch: 0007 cost = 0.744411\n",
      "Epoch: 0008 cost = 0.741552\n",
      "Epoch: 0009 cost = 0.738744\n",
      "Epoch: 0010 cost = 0.735965\n",
      "Epoch: 0011 cost = 0.733219\n",
      "Epoch: 0012 cost = 0.730507\n",
      "Epoch: 0013 cost = 0.727827\n",
      "Epoch: 0014 cost = 0.725162\n",
      "Epoch: 0015 cost = 0.722527\n",
      "Epoch: 0016 cost = 0.719922\n",
      "Epoch: 0017 cost = 0.717345\n",
      "Epoch: 0018 cost = 0.714795\n",
      "Epoch: 0019 cost = 0.712271\n",
      "Epoch: 0020 cost = 0.709770\n",
      "Epoch: 0021 cost = 0.707293\n",
      "Epoch: 0022 cost = 0.704836\n",
      "Epoch: 0023 cost = 0.702399\n",
      "Epoch: 0024 cost = 0.699980\n",
      "Epoch: 0025 cost = 0.697578\n",
      "Epoch: 0026 cost = 0.695190\n",
      "Epoch: 0027 cost = 0.692790\n",
      "Epoch: 0028 cost = 0.690402\n",
      "Epoch: 0029 cost = 0.688026\n",
      "Epoch: 0030 cost = 0.685662\n",
      "Epoch: 0031 cost = 0.683293\n",
      "Epoch: 0032 cost = 0.680926\n",
      "Epoch: 0033 cost = 0.678567\n",
      "Epoch: 0034 cost = 0.676267\n",
      "Epoch: 0035 cost = 0.673993\n",
      "Epoch: 0036 cost = 0.671714\n",
      "Epoch: 0037 cost = 0.669432\n",
      "Epoch: 0038 cost = 0.667161\n",
      "Epoch: 0039 cost = 0.664889\n",
      "Epoch: 0040 cost = 0.662611\n",
      "Epoch: 0041 cost = 0.660329\n",
      "Epoch: 0042 cost = 0.658044\n",
      "Epoch: 0043 cost = 0.655771\n",
      "Epoch: 0044 cost = 0.653548\n",
      "Epoch: 0045 cost = 0.651328\n",
      "Epoch: 0046 cost = 0.649100\n",
      "Epoch: 0047 cost = 0.646867\n",
      "Epoch: 0048 cost = 0.644629\n",
      "Epoch: 0049 cost = 0.642387\n",
      "Epoch: 0050 cost = 0.640140\n",
      "Epoch: 0051 cost = 0.637889\n",
      "Epoch: 0052 cost = 0.635634\n",
      "Epoch: 0053 cost = 0.633381\n",
      "Epoch: 0054 cost = 0.631150\n",
      "Epoch: 0055 cost = 0.628908\n",
      "Epoch: 0056 cost = 0.626659\n",
      "Epoch: 0057 cost = 0.624396\n",
      "Epoch: 0058 cost = 0.622145\n",
      "Epoch: 0059 cost = 0.619894\n",
      "Epoch: 0060 cost = 0.617633\n",
      "Epoch: 0061 cost = 0.615360\n",
      "Epoch: 0062 cost = 0.613077\n",
      "Epoch: 0063 cost = 0.610789\n",
      "Epoch: 0064 cost = 0.608504\n",
      "Epoch: 0065 cost = 0.606271\n",
      "Epoch: 0066 cost = 0.604033\n",
      "Epoch: 0067 cost = 0.601767\n",
      "Epoch: 0068 cost = 0.599473\n",
      "Epoch: 0069 cost = 0.597158\n",
      "Epoch: 0070 cost = 0.594823\n",
      "Epoch: 0071 cost = 0.592519\n",
      "Epoch: 0072 cost = 0.590222\n",
      "Epoch: 0073 cost = 0.587910\n",
      "Epoch: 0074 cost = 0.585584\n",
      "Epoch: 0075 cost = 0.583247\n",
      "Epoch: 0076 cost = 0.580892\n",
      "Epoch: 0077 cost = 0.578530\n",
      "Epoch: 0078 cost = 0.576153\n",
      "Epoch: 0079 cost = 0.573758\n",
      "Epoch: 0080 cost = 0.571354\n",
      "Epoch: 0081 cost = 0.568935\n",
      "Epoch: 0082 cost = 0.566504\n",
      "Epoch: 0083 cost = 0.564093\n",
      "Epoch: 0084 cost = 0.561648\n",
      "Epoch: 0085 cost = 0.559197\n",
      "Epoch: 0086 cost = 0.556741\n",
      "Epoch: 0087 cost = 0.554262\n",
      "Epoch: 0088 cost = 0.551775\n",
      "Epoch: 0089 cost = 0.549291\n",
      "Epoch: 0090 cost = 0.546778\n",
      "Epoch: 0091 cost = 0.544248\n",
      "Epoch: 0092 cost = 0.541729\n",
      "Epoch: 0093 cost = 0.539188\n",
      "Epoch: 0094 cost = 0.536623\n",
      "Epoch: 0095 cost = 0.534054\n",
      "Epoch: 0096 cost = 0.531483\n",
      "Epoch: 0097 cost = 0.528889\n",
      "Epoch: 0098 cost = 0.526287\n",
      "Epoch: 0099 cost = 0.523665\n",
      "Epoch: 0100 cost = 0.521025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_model(model,inputs,targets,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he hate you is Good Mean!!\n"
     ]
    }
   ],
   "source": [
    "test_text = 'he hate you'\n",
    "tests = [np.asarray([word_dict[n] for n in test_text.split()])]\n",
    "test_input = torch.LongTensor(tests)\n",
    "prediction = test_model(model,test_input)\n",
    "\n",
    "if prediction == 0:\n",
    "    print(test_text,\"is Bad Mean...\")\n",
    "else:\n",
    "    print(test_text,\"is Good Mean!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 What is Batch Normalization?\n",
    "- `normalization`\n",
    "    - 정규화 : 데이터 범위를 사용자가 원하는 범위로 제한하는 것\n",
    "        - feature scaling으로도 불림\n",
    "    - 방법\n",
    "        - [nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train vanilla model + batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       "  (batch_norm_list): ModuleList(\n",
       "    (0-2): 3 x BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batchnormalized = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes,is_batch_normalize=True\n",
    ")\n",
    "model_batchnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.546563\n",
      "Epoch: 0002 cost = 0.532212\n",
      "Epoch: 0003 cost = 0.518653\n",
      "Epoch: 0004 cost = 0.505375\n",
      "Epoch: 0005 cost = 0.491775\n",
      "Epoch: 0006 cost = 0.477543\n",
      "Epoch: 0007 cost = 0.462534\n",
      "Epoch: 0008 cost = 0.446795\n",
      "Epoch: 0009 cost = 0.431129\n",
      "Epoch: 0010 cost = 0.420883\n",
      "Epoch: 0011 cost = 0.416298\n",
      "Epoch: 0012 cost = 0.410644\n",
      "Epoch: 0013 cost = 0.404155\n",
      "Epoch: 0014 cost = 0.397225\n",
      "Epoch: 0015 cost = 0.390195\n",
      "Epoch: 0016 cost = 0.383286\n",
      "Epoch: 0017 cost = 0.376609\n",
      "Epoch: 0018 cost = 0.370202\n",
      "Epoch: 0019 cost = 0.364071\n",
      "Epoch: 0020 cost = 0.358207\n",
      "Epoch: 0021 cost = 0.353755\n",
      "Epoch: 0022 cost = 0.350179\n",
      "Epoch: 0023 cost = 0.346632\n",
      "Epoch: 0024 cost = 0.343124\n",
      "Epoch: 0025 cost = 0.340613\n",
      "Epoch: 0026 cost = 0.337502\n",
      "Epoch: 0027 cost = 0.333660\n",
      "Epoch: 0028 cost = 0.330041\n",
      "Epoch: 0029 cost = 0.327010\n",
      "Epoch: 0030 cost = 0.324023\n",
      "Epoch: 0031 cost = 0.321086\n",
      "Epoch: 0032 cost = 0.318202\n",
      "Epoch: 0033 cost = 0.315374\n",
      "Epoch: 0034 cost = 0.312601\n",
      "Epoch: 0035 cost = 0.309883\n",
      "Epoch: 0036 cost = 0.307218\n",
      "Epoch: 0037 cost = 0.304603\n",
      "Epoch: 0038 cost = 0.302034\n",
      "Epoch: 0039 cost = 0.299510\n",
      "Epoch: 0040 cost = 0.297025\n",
      "Epoch: 0041 cost = 0.294576\n",
      "Epoch: 0042 cost = 0.292160\n",
      "Epoch: 0043 cost = 0.289773\n",
      "Epoch: 0044 cost = 0.287593\n",
      "Epoch: 0045 cost = 0.285416\n",
      "Epoch: 0046 cost = 0.283210\n",
      "Epoch: 0047 cost = 0.280976\n",
      "Epoch: 0048 cost = 0.278716\n",
      "Epoch: 0049 cost = 0.276433\n",
      "Epoch: 0050 cost = 0.274129\n",
      "Epoch: 0051 cost = 0.271913\n",
      "Epoch: 0052 cost = 0.269776\n",
      "Epoch: 0053 cost = 0.267643\n",
      "Epoch: 0054 cost = 0.265504\n",
      "Epoch: 0055 cost = 0.263360\n",
      "Epoch: 0056 cost = 0.261212\n",
      "Epoch: 0057 cost = 0.259064\n",
      "Epoch: 0058 cost = 0.256917\n",
      "Epoch: 0059 cost = 0.254772\n",
      "Epoch: 0060 cost = 0.252631\n",
      "Epoch: 0061 cost = 0.250496\n",
      "Epoch: 0062 cost = 0.248367\n",
      "Epoch: 0063 cost = 0.246245\n",
      "Epoch: 0064 cost = 0.244195\n",
      "Epoch: 0065 cost = 0.242145\n",
      "Epoch: 0066 cost = 0.240082\n",
      "Epoch: 0067 cost = 0.237997\n",
      "Epoch: 0068 cost = 0.235966\n",
      "Epoch: 0069 cost = 0.233934\n",
      "Epoch: 0070 cost = 0.231905\n",
      "Epoch: 0071 cost = 0.229875\n",
      "Epoch: 0072 cost = 0.227846\n",
      "Epoch: 0073 cost = 0.225815\n",
      "Epoch: 0074 cost = 0.223785\n",
      "Epoch: 0075 cost = 0.221792\n",
      "Epoch: 0076 cost = 0.219760\n",
      "Epoch: 0077 cost = 0.217728\n",
      "Epoch: 0078 cost = 0.215873\n",
      "Epoch: 0079 cost = 0.214006\n",
      "Epoch: 0080 cost = 0.212125\n",
      "Epoch: 0081 cost = 0.210233\n",
      "Epoch: 0082 cost = 0.208333\n",
      "Epoch: 0083 cost = 0.206427\n",
      "Epoch: 0084 cost = 0.204517\n",
      "Epoch: 0085 cost = 0.202700\n",
      "Epoch: 0086 cost = 0.200950\n",
      "Epoch: 0087 cost = 0.199213\n",
      "Epoch: 0088 cost = 0.197438\n",
      "Epoch: 0089 cost = 0.195651\n",
      "Epoch: 0090 cost = 0.193878\n",
      "Epoch: 0091 cost = 0.192092\n",
      "Epoch: 0092 cost = 0.190296\n",
      "Epoch: 0093 cost = 0.188491\n",
      "Epoch: 0094 cost = 0.186678\n",
      "Epoch: 0095 cost = 0.184857\n",
      "Epoch: 0096 cost = 0.183072\n",
      "Epoch: 0097 cost = 0.181430\n",
      "Epoch: 0098 cost = 0.179772\n",
      "Epoch: 0099 cost = 0.178069\n",
      "Epoch: 0100 cost = 0.176324\n"
     ]
    }
   ],
   "source": [
    "train_model(model_batchnormalized,inputs,targets,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 What is Drop Out?\n",
    "- drop out \n",
    "    - 드롭아웃 : 학습 시 , 일정 비율의 뉴런만 사용하고 나머지 뉴런에 해당하는 가중치는 업데이트 하지 않는 방법\n",
    "        - 매 단계마다 사용하지 않는 뉴런을 바꾼다.\n",
    "    - 방법 \n",
    "        - [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train & test vanilla model + dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes, dropout_prob = 0.5\n",
    ")\n",
    "model_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.835831\n",
      "Epoch: 0002 cost = 0.839361\n",
      "Epoch: 0003 cost = 1.023070\n",
      "Epoch: 0004 cost = 1.100236\n",
      "Epoch: 0005 cost = 1.013633\n",
      "Epoch: 0006 cost = 0.814668\n",
      "Epoch: 0007 cost = 0.749790\n",
      "Epoch: 0008 cost = 1.029342\n",
      "Epoch: 0009 cost = 0.898030\n",
      "Epoch: 0010 cost = 0.959308\n",
      "Epoch: 0011 cost = 1.000341\n",
      "Epoch: 0012 cost = 0.697045\n",
      "Epoch: 0013 cost = 0.700373\n",
      "Epoch: 0014 cost = 0.771796\n",
      "Epoch: 0015 cost = 0.844553\n",
      "Epoch: 0016 cost = 0.744747\n",
      "Epoch: 0017 cost = 1.010743\n",
      "Epoch: 0018 cost = 0.891656\n",
      "Epoch: 0019 cost = 0.850598\n",
      "Epoch: 0020 cost = 0.873699\n",
      "Epoch: 0021 cost = 0.858110\n",
      "Epoch: 0022 cost = 0.988086\n",
      "Epoch: 0023 cost = 0.898695\n",
      "Epoch: 0024 cost = 0.735082\n",
      "Epoch: 0025 cost = 0.838922\n",
      "Epoch: 0026 cost = 0.967191\n",
      "Epoch: 0027 cost = 0.829715\n",
      "Epoch: 0028 cost = 0.908104\n",
      "Epoch: 0029 cost = 0.983906\n",
      "Epoch: 0030 cost = 0.854923\n",
      "Epoch: 0031 cost = 0.757845\n",
      "Epoch: 0032 cost = 0.746741\n",
      "Epoch: 0033 cost = 0.777772\n",
      "Epoch: 0034 cost = 0.638498\n",
      "Epoch: 0035 cost = 0.800358\n",
      "Epoch: 0036 cost = 0.742130\n",
      "Epoch: 0037 cost = 0.776772\n",
      "Epoch: 0038 cost = 0.829891\n",
      "Epoch: 0039 cost = 0.886790\n",
      "Epoch: 0040 cost = 0.818059\n",
      "Epoch: 0041 cost = 0.855233\n",
      "Epoch: 0042 cost = 0.871971\n",
      "Epoch: 0043 cost = 1.106352\n",
      "Epoch: 0044 cost = 0.703313\n",
      "Epoch: 0045 cost = 0.852387\n",
      "Epoch: 0046 cost = 0.904891\n",
      "Epoch: 0047 cost = 0.720621\n",
      "Epoch: 0048 cost = 0.858346\n",
      "Epoch: 0049 cost = 0.694336\n",
      "Epoch: 0050 cost = 0.793954\n",
      "Epoch: 0051 cost = 0.748608\n",
      "Epoch: 0052 cost = 0.927909\n",
      "Epoch: 0053 cost = 0.815317\n",
      "Epoch: 0054 cost = 0.763027\n",
      "Epoch: 0055 cost = 0.709272\n",
      "Epoch: 0056 cost = 0.808757\n",
      "Epoch: 0057 cost = 0.835018\n",
      "Epoch: 0058 cost = 0.859500\n",
      "Epoch: 0059 cost = 0.912871\n",
      "Epoch: 0060 cost = 0.673860\n",
      "Epoch: 0061 cost = 0.793919\n",
      "Epoch: 0062 cost = 0.943766\n",
      "Epoch: 0063 cost = 0.848429\n",
      "Epoch: 0064 cost = 0.776532\n",
      "Epoch: 0065 cost = 0.890209\n",
      "Epoch: 0066 cost = 0.795771\n",
      "Epoch: 0067 cost = 0.678452\n",
      "Epoch: 0068 cost = 0.831130\n",
      "Epoch: 0069 cost = 0.777394\n",
      "Epoch: 0070 cost = 0.751798\n",
      "Epoch: 0071 cost = 0.808280\n",
      "Epoch: 0072 cost = 0.606679\n",
      "Epoch: 0073 cost = 0.779896\n",
      "Epoch: 0074 cost = 0.650368\n",
      "Epoch: 0075 cost = 0.830568\n",
      "Epoch: 0076 cost = 0.692488\n",
      "Epoch: 0077 cost = 0.825588\n",
      "Epoch: 0078 cost = 0.736214\n",
      "Epoch: 0079 cost = 0.876871\n",
      "Epoch: 0080 cost = 0.755987\n",
      "Epoch: 0081 cost = 0.830164\n",
      "Epoch: 0082 cost = 0.768272\n",
      "Epoch: 0083 cost = 0.752991\n",
      "Epoch: 0084 cost = 0.688215\n",
      "Epoch: 0085 cost = 0.714668\n",
      "Epoch: 0086 cost = 0.727743\n",
      "Epoch: 0087 cost = 0.781768\n",
      "Epoch: 0088 cost = 0.727148\n",
      "Epoch: 0089 cost = 0.770283\n",
      "Epoch: 0090 cost = 0.662515\n",
      "Epoch: 0091 cost = 0.663976\n",
      "Epoch: 0092 cost = 0.737670\n",
      "Epoch: 0093 cost = 0.711786\n",
      "Epoch: 0094 cost = 0.785711\n",
      "Epoch: 0095 cost = 0.768264\n",
      "Epoch: 0096 cost = 0.763673\n",
      "Epoch: 0097 cost = 0.641406\n",
      "Epoch: 0098 cost = 0.685755\n",
      "Epoch: 0099 cost = 0.682436\n",
      "Epoch: 0100 cost = 0.836684\n"
     ]
    }
   ],
   "source": [
    "train_model(model_dropout,inputs,targets,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 What is Early Stopping?\n",
    "- early stopping\n",
    "    - 조기 종료: 검증 데이터셋에 대한 오차가 증가하는 시점에 학습을 멈추도록 조정\n",
    "    - 방법\n",
    "        - [참고 코드](https://teddylee777.github.io/pytorch/early-stopping/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train vanilla model with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.720871\n",
      "Epoch: 0002 cost = 0.814197\n",
      "Epoch: 0003 cost = 0.668677\n",
      "Epoch: 0004 cost = 0.706945\n",
      "Epoch: 0005 cost = 0.696048\n",
      "Epoch: 0006 cost = 0.760279\n",
      "Epoch: 0007 cost = 0.642941\n",
      "Epoch: 0008 cost = 0.622185\n",
      "Epoch: 0009 cost = 0.771354\n",
      "Epoch: 0010 cost = 0.762187\n",
      "Epoch: 0011 cost = 0.692801\n",
      "Epoch: 0012 cost = 0.675045\n",
      "Epoch: 0013 cost = 0.620510\n",
      "Epoch: 0014 cost = 0.645030\n",
      "Epoch: 0015 cost = 0.702103\n",
      "Epoch: 0016 cost = 0.743795\n",
      "Epoch: 0017 cost = 0.698649\n",
      "Epoch: 0018 cost = 0.694609\n",
      "Early stopping at epoch 18 due to lack of improvement.\n"
     ]
    }
   ],
   "source": [
    "train_model_with_early_stop(model_dropout,inputs,targets,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23-2_MMStudy_Analysis_F-O1JOBGQa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
