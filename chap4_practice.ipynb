{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. 딥러닝 시작**\n",
    "#### **목차**\n",
    "- 4.1. 인공 신경망의 한계와 딥러닝 출현\n",
    "- 4.2. 딥러닝 구조\n",
    "- 4.3. 딥러닝 알고리즘\n",
    "- 4.4. 우리는 무엇을 배워야할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2. 딥러닝 구조**\n",
    "##### 4.2.3 딥러닝의 문제점과 해결 방안\n",
    "- 딥러닝의 핵심 \n",
    "    - 활성화 함수가 적용된 여러 은닉층을 결합하여 비선형 영역을 표현하는 것\n",
    "    - 활성화 함수가 적용된 은닉층 개수가 많을 수록 **훈련데이터**에 대해서는 데이터 분류가 잘 된다.\n",
    "- 딥러닝 학습 과정에서 발생할 수 있는 문제와 해결 방법\n",
    "    - 과적합\n",
    "        - 위처럼 훈련 데이터에 대해 과하게 학습하면, **실제 데이터** 에 대한 오차가 발생하는 과적합 현상이 발생한다.\n",
    "        - 해결 방법\n",
    "            - 드롭아웃 : 학습 과정 중 임의로 일부 노드들을 학습에서 제외시킨다.\n",
    "            - 배치 정규화\n",
    "    - 기울기 소멸\n",
    "        - 은닉층이 많은 신경망에서 주로 발생, 출력층에서 은닉층으로 전달되는 오차가 크게 줄어 들어 학습이 되지 않는 현상이다.\n",
    "        - 해결 방법\n",
    "            - 시그모이드 또는 하이퍼볼릭 탄젠트 활성화 함수를 사용했다면, 렐루 활성화 함수로 대체\n",
    "    - 성능이 나빠지는 문제 발생\n",
    "        - 경사 하강법을 반복하다보면, 성능이 나빠진다.\n",
    "        - 해결 방법\n",
    "            - 확률적 경사 하강법\n",
    "                - 파라미터 변경 폭이 불안정 한 문제가 있다.\n",
    "                    - 해결 방법\n",
    "                        - 학습 속도와 운동량을 조정하는 옵티마이저 적용\n",
    "            - 미니 배치 경사 하강법\n",
    "##### 4.2.4 딥러닝을 사용할 때 이점\n",
    "- 특성 추출\n",
    "    - 데이터 별로 어떤 특징을 가지고 있는 지 찾아내고, 특징을 토대로 데이터를 벡터로 변환하는 작업\n",
    "    - 데이터가 많을 수록 성능이 향상된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "- Inputs: tensor([[ 3.,  6.,  9.],\n",
      "        [ 4.,  8., 12.]])\n",
      "- Targets: tensor([[11.],\n",
      "        [14.]])\n",
      "- Batch size: 2\n",
      "\n",
      "Batch 2\n",
      "- Inputs: tensor([[2., 4., 6.],\n",
      "        [1., 2., 3.]])\n",
      "- Targets: tensor([[18.],\n",
      "        [12.]])\n",
      "- Batch size: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.2.3 미니 배치 경사 하강법 실습\n",
    "from dataset import CustomDataset\n",
    "from data import load_data_using_mini_batch \n",
    "\n",
    "dataset = CustomDataset()\n",
    "mini_batch_size = 2\n",
    "dataloader = load_data_using_mini_batch(dataset,mini_batch_size)\n",
    "\n",
    "for batch_num,batch in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_num + 1}\")\n",
    "    inputs, targets = batch\n",
    "    print(\"- Inputs:\", inputs)\n",
    "    print(\"- Targets:\", targets)\n",
    "    print(\"- Batch size:\", inputs.size(0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. 딥러닝 알고리즘\n",
    "##### 4.3.1 심층 신경망\n",
    "- 심층 신경망(DNN): 입력층과 출력층 사이에 다수의 은닉층을 포함하는 인공 신경망\n",
    "##### 4.3.2 합성곱 신경망\n",
    "- 합성곱 신경망(CNN): convolution layer 와 pooling layer을 포함하는 이미지 처리 성능이 좋은 인공 신경망 알고리즘\n",
    "    - 기존 신경망과의 차별성\n",
    "        - 각 층의 입출력 형상을 유지\n",
    "        - 이미지의 공간 정보를 유지하면서 인접 이미지와 차이가 있는 특징을 효과적으로 인식\n",
    "        - 복수 필터로 이미지의 특징을 추출하고 학습\n",
    "        - 추출한 이미지의 특징을 모으고 강화하는 풀링층\n",
    "        - 필터를 공유 파라미터로 사용하기 때문에 학습 파라미터가 매우 적음\n",
    "##### 4.3.3 순환 신경망\n",
    "- 순환 신경망(RNN): 시계열 데이터 같은 시간 흐름에 따라 변화하는 데이터를 학습하기 위한 인공 신경망\n",
    "    - 순환(recurrent): 자기 자신을 참조한다는 것, 현재 결과가 이전 결과와 연관이 있다는 의미\n",
    "    - 특징\n",
    "        - 시간에 따라 내용이 변하므로 데이터는 동적이고 길이가 가변적.\n",
    "        - 매우 긴 데이터를 처리하는 연구가 활발히 진행되고 있음.\n",
    "        - 기울기 소멸 문제로 학습이 제대로 되지 않는 문제\n",
    "            - 해결방안\n",
    "                - LSTM(Long-short Term Memory)\n",
    "##### 4.3.4 제한된 볼츠만 머신\n",
    "- 볼츠만 머신: 가시층과 은닉층으로 구성된 모델\n",
    "    - 제한된 볼츠만 머신: 가시층은 은닉층과만 연결된다.\n",
    "        - 특징\n",
    "            - 차원 감소, 분류, 선형 회귀 분석, 협업 필터링, 특성 값 학습, 주제모델링에 사용\n",
    "            - 기울기 소멸 문제를 해결하기 위해 사전 학습 용도로 활용 가능\n",
    "            - 심층 신뢰 신경망의 요소로 활용\n",
    "##### 4.3.5 심층 신뢰 신경망\n",
    "- 심층 신뢰 신경망(Deep Belief Network, DBN): 입력층과 은닉층으로 구성된 제한된 볼츠만 머신(사전 훈련된)을 블록처럼 여러 층으로 쌓은 신경망\n",
    "- 특징:\n",
    "    - 비지도 학습 가능\n",
    "        - 부분적인 이미지에서 전체를 연상하는 일반화화 추상화 과정을 구현할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23-2_MMStudy_Analysis_F-O1JOBGQa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
