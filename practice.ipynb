{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import text_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"i love you\", \"he loves me\", \"she likes baseball\", \"i hate you\", \"sorry for that\", \"this is awful\"]\n",
    "labels = [1, 1, 1, 0, 0, 0]  # 1 is good, 0 is not good.\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 3 \n",
    "filter_sizes = [2, 2, 2] \n",
    "vocab_size = len(word_dict)\n",
    "embedding_size = 2 \n",
    "sequence_length = 3 \n",
    "num_classes = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       "  (batch_norm_list): ModuleList(\n",
       "    (0-2): 3 x BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.668719\n",
      "Epoch: 0002 cost = 0.667259\n",
      "Epoch: 0003 cost = 0.665808\n",
      "Epoch: 0004 cost = 0.664365\n",
      "Epoch: 0005 cost = 0.662931\n",
      "Epoch: 0006 cost = 0.661505\n",
      "Epoch: 0007 cost = 0.660086\n",
      "Epoch: 0008 cost = 0.658674\n",
      "Epoch: 0009 cost = 0.657266\n",
      "Epoch: 0010 cost = 0.655860\n",
      "Epoch: 0011 cost = 0.654456\n",
      "Epoch: 0012 cost = 0.653061\n",
      "Epoch: 0013 cost = 0.651667\n",
      "Epoch: 0014 cost = 0.650268\n",
      "Epoch: 0015 cost = 0.648865\n",
      "Epoch: 0016 cost = 0.647456\n",
      "Epoch: 0017 cost = 0.646042\n",
      "Epoch: 0018 cost = 0.644620\n",
      "Epoch: 0019 cost = 0.643191\n",
      "Epoch: 0020 cost = 0.641753\n",
      "Epoch: 0021 cost = 0.640306\n",
      "Epoch: 0022 cost = 0.638849\n",
      "Epoch: 0023 cost = 0.637380\n",
      "Epoch: 0024 cost = 0.635899\n",
      "Epoch: 0025 cost = 0.634406\n",
      "Epoch: 0026 cost = 0.632901\n",
      "Epoch: 0027 cost = 0.631384\n",
      "Epoch: 0028 cost = 0.629853\n",
      "Epoch: 0029 cost = 0.628306\n",
      "Epoch: 0030 cost = 0.626755\n",
      "Epoch: 0031 cost = 0.625193\n",
      "Epoch: 0032 cost = 0.623617\n",
      "Epoch: 0033 cost = 0.622027\n",
      "Epoch: 0034 cost = 0.620423\n",
      "Epoch: 0035 cost = 0.618805\n",
      "Epoch: 0036 cost = 0.617174\n",
      "Epoch: 0037 cost = 0.615528\n",
      "Epoch: 0038 cost = 0.613899\n",
      "Epoch: 0039 cost = 0.612282\n",
      "Epoch: 0040 cost = 0.610649\n",
      "Epoch: 0041 cost = 0.608999\n",
      "Epoch: 0042 cost = 0.607334\n",
      "Epoch: 0043 cost = 0.605653\n",
      "Epoch: 0044 cost = 0.603957\n",
      "Epoch: 0045 cost = 0.602246\n",
      "Epoch: 0046 cost = 0.600519\n",
      "Epoch: 0047 cost = 0.598777\n",
      "Epoch: 0048 cost = 0.597020\n",
      "Epoch: 0049 cost = 0.595249\n",
      "Epoch: 0050 cost = 0.593462\n",
      "Epoch: 0051 cost = 0.591660\n",
      "Epoch: 0052 cost = 0.589844\n",
      "Epoch: 0053 cost = 0.588012\n",
      "Epoch: 0054 cost = 0.586166\n",
      "Epoch: 0055 cost = 0.584305\n",
      "Epoch: 0056 cost = 0.582429\n",
      "Epoch: 0057 cost = 0.580539\n",
      "Epoch: 0058 cost = 0.578634\n",
      "Epoch: 0059 cost = 0.576714\n",
      "Epoch: 0060 cost = 0.574780\n",
      "Epoch: 0061 cost = 0.572838\n",
      "Epoch: 0062 cost = 0.570897\n",
      "Epoch: 0063 cost = 0.568931\n",
      "Epoch: 0064 cost = 0.566940\n",
      "Epoch: 0065 cost = 0.564934\n",
      "Epoch: 0066 cost = 0.562928\n",
      "Epoch: 0067 cost = 0.560907\n",
      "Epoch: 0068 cost = 0.558871\n",
      "Epoch: 0069 cost = 0.556819\n",
      "Epoch: 0070 cost = 0.554753\n",
      "Epoch: 0071 cost = 0.552672\n",
      "Epoch: 0072 cost = 0.550576\n",
      "Epoch: 0073 cost = 0.548473\n",
      "Epoch: 0074 cost = 0.546355\n",
      "Epoch: 0075 cost = 0.544221\n",
      "Epoch: 0076 cost = 0.542079\n",
      "Epoch: 0077 cost = 0.539922\n",
      "Epoch: 0078 cost = 0.537758\n",
      "Epoch: 0079 cost = 0.535572\n",
      "Epoch: 0080 cost = 0.533380\n",
      "Epoch: 0081 cost = 0.531177\n",
      "Epoch: 0082 cost = 0.528961\n",
      "Epoch: 0083 cost = 0.526733\n",
      "Epoch: 0084 cost = 0.524495\n",
      "Epoch: 0085 cost = 0.522244\n",
      "Epoch: 0086 cost = 0.519973\n",
      "Epoch: 0087 cost = 0.517601\n",
      "Epoch: 0088 cost = 0.515215\n",
      "Epoch: 0089 cost = 0.512817\n",
      "Epoch: 0090 cost = 0.510375\n",
      "Epoch: 0091 cost = 0.507918\n",
      "Epoch: 0092 cost = 0.505463\n",
      "Epoch: 0093 cost = 0.502989\n",
      "Epoch: 0094 cost = 0.500493\n",
      "Epoch: 0095 cost = 0.498108\n",
      "Epoch: 0096 cost = 0.495703\n",
      "Epoch: 0097 cost = 0.493281\n",
      "Epoch: 0098 cost = 0.490817\n",
      "Epoch: 0099 cost = 0.488315\n",
      "Epoch: 0100 cost = 0.485777\n",
      "he hate you is Good Mean!!\n"
     ]
    }
   ],
   "source": [
    "model = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "inputs = torch.LongTensor([np.asarray([word_dict[n] for n in sen.split()]) for sen in sentences])\n",
    "targets = torch.LongTensor([out for out in labels]) # To using Torch Softmax Loss function\n",
    "\n",
    "# Training\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(inputs)\n",
    "\n",
    "    # output : [batch_size, num_classes], target_batch : [batch_size] (LongTensor, not one-hot)\n",
    "    loss = criterion(output, targets)\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    " \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "test_text = 'he hate you'\n",
    "tests = [np.asarray([word_dict[n] for n in test_text.split()])]\n",
    "test_batch = torch.LongTensor(tests)\n",
    "\n",
    "# Predict\n",
    "predict = model(test_batch).data.max(1, keepdim=True)[1]\n",
    "if predict[0][0] == 0:\n",
    "    print(test_text,\"is Bad Mean...\")\n",
    "else:\n",
    "    print(test_text,\"is Good Mean!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (W): Embedding(16, 2)\n",
       "  (Weight): Linear(in_features=9, out_features=2, bias=False)\n",
       "  (filter_list): ModuleList(\n",
       "    (0-2): 3 x Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  )\n",
       "  (batch_norm_list): ModuleList(\n",
       "    (0-2): 3 x BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.784973\n",
      "Epoch: 0002 cost = 0.774597\n",
      "Epoch: 0003 cost = 0.764506\n",
      "Epoch: 0004 cost = 0.754701\n",
      "Epoch: 0005 cost = 0.745181\n",
      "Epoch: 0006 cost = 0.735939\n",
      "Epoch: 0007 cost = 0.726968\n",
      "Epoch: 0008 cost = 0.718814\n",
      "Epoch: 0009 cost = 0.710768\n",
      "Epoch: 0010 cost = 0.702837\n",
      "Epoch: 0011 cost = 0.695028\n",
      "Epoch: 0012 cost = 0.687339\n",
      "Epoch: 0013 cost = 0.679760\n",
      "Epoch: 0014 cost = 0.672283\n",
      "Epoch: 0015 cost = 0.664895\n",
      "Epoch: 0016 cost = 0.657579\n",
      "Epoch: 0017 cost = 0.650321\n",
      "Epoch: 0018 cost = 0.643109\n",
      "Epoch: 0019 cost = 0.635927\n",
      "Epoch: 0020 cost = 0.628943\n",
      "Epoch: 0021 cost = 0.621962\n",
      "Epoch: 0022 cost = 0.614938\n",
      "Epoch: 0023 cost = 0.607859\n",
      "Epoch: 0024 cost = 0.600757\n",
      "Epoch: 0025 cost = 0.593628\n",
      "Epoch: 0026 cost = 0.586453\n",
      "Epoch: 0027 cost = 0.579147\n",
      "Epoch: 0028 cost = 0.571704\n",
      "Epoch: 0029 cost = 0.564150\n",
      "Epoch: 0030 cost = 0.556454\n",
      "Epoch: 0031 cost = 0.548588\n",
      "Epoch: 0032 cost = 0.540539\n",
      "Epoch: 0033 cost = 0.532375\n",
      "Epoch: 0034 cost = 0.524589\n",
      "Epoch: 0035 cost = 0.519719\n",
      "Epoch: 0036 cost = 0.514845\n",
      "Epoch: 0037 cost = 0.509979\n",
      "Epoch: 0038 cost = 0.505152\n",
      "Epoch: 0039 cost = 0.500344\n",
      "Epoch: 0040 cost = 0.495543\n",
      "Epoch: 0041 cost = 0.490866\n",
      "Epoch: 0042 cost = 0.487499\n",
      "Epoch: 0043 cost = 0.484139\n",
      "Epoch: 0044 cost = 0.480847\n",
      "Epoch: 0045 cost = 0.477530\n",
      "Epoch: 0046 cost = 0.474186\n",
      "Epoch: 0047 cost = 0.470861\n",
      "Epoch: 0048 cost = 0.467557\n",
      "Epoch: 0049 cost = 0.464262\n",
      "Epoch: 0050 cost = 0.460984\n",
      "Epoch: 0051 cost = 0.457722\n",
      "Epoch: 0052 cost = 0.454484\n",
      "Epoch: 0053 cost = 0.451251\n",
      "Epoch: 0054 cost = 0.448020\n",
      "Epoch: 0055 cost = 0.444794\n",
      "Epoch: 0056 cost = 0.441709\n",
      "Epoch: 0057 cost = 0.438609\n",
      "Epoch: 0058 cost = 0.435488\n",
      "Epoch: 0059 cost = 0.432353\n",
      "Epoch: 0060 cost = 0.429209\n",
      "Epoch: 0061 cost = 0.426056\n",
      "Epoch: 0062 cost = 0.422964\n",
      "Epoch: 0063 cost = 0.419870\n",
      "Epoch: 0064 cost = 0.416718\n",
      "Epoch: 0065 cost = 0.413569\n",
      "Epoch: 0066 cost = 0.410519\n",
      "Epoch: 0067 cost = 0.407474\n",
      "Epoch: 0068 cost = 0.404369\n",
      "Epoch: 0069 cost = 0.401216\n",
      "Epoch: 0070 cost = 0.398087\n",
      "Epoch: 0071 cost = 0.394968\n",
      "Epoch: 0072 cost = 0.391817\n",
      "Epoch: 0073 cost = 0.388709\n",
      "Epoch: 0074 cost = 0.385578\n",
      "Epoch: 0075 cost = 0.382462\n",
      "Epoch: 0076 cost = 0.379291\n",
      "Epoch: 0077 cost = 0.376164\n",
      "Epoch: 0078 cost = 0.372998\n",
      "Epoch: 0079 cost = 0.369881\n",
      "Epoch: 0080 cost = 0.366768\n",
      "Epoch: 0081 cost = 0.363622\n",
      "Epoch: 0082 cost = 0.360436\n",
      "Epoch: 0083 cost = 0.357212\n",
      "Epoch: 0084 cost = 0.354016\n",
      "Epoch: 0085 cost = 0.350786\n",
      "Epoch: 0086 cost = 0.347541\n",
      "Epoch: 0087 cost = 0.344610\n",
      "Epoch: 0088 cost = 0.341143\n",
      "Epoch: 0089 cost = 0.337981\n",
      "Epoch: 0090 cost = 0.334827\n",
      "Epoch: 0091 cost = 0.331647\n",
      "Epoch: 0092 cost = 0.328430\n",
      "Epoch: 0093 cost = 0.325177\n",
      "Epoch: 0094 cost = 0.321918\n",
      "Epoch: 0095 cost = 0.318674\n",
      "Epoch: 0096 cost = 0.315387\n",
      "Epoch: 0097 cost = 0.312081\n",
      "Epoch: 0098 cost = 0.308743\n",
      "Epoch: 0099 cost = 0.305388\n",
      "Epoch: 0100 cost = 0.302046\n",
      "he hate you is Good Mean!!\n"
     ]
    }
   ],
   "source": [
    "model = text_cnn.TextCNN(\n",
    "    num_filters, filter_sizes, vocab_size,\n",
    "    embedding_size, sequence_length, num_classes,is_batch_normalize=True\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "inputs = torch.LongTensor([np.asarray([word_dict[n] for n in sen.split()]) for sen in sentences])\n",
    "targets = torch.LongTensor([out for out in labels]) # To using Torch Softmax Loss function\n",
    "\n",
    "# Training\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(inputs)\n",
    "\n",
    "    # output : [batch_size, num_classes], target_batch : [batch_size] (LongTensor, not one-hot)\n",
    "    loss = criterion(output, targets)\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    " \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "test_text = 'he hate you'\n",
    "tests = [np.asarray([word_dict[n] for n in test_text.split()])]\n",
    "test_batch = torch.LongTensor(tests)\n",
    "\n",
    "# Predict\n",
    "predict = model(test_batch).data.max(1, keepdim=True)[1]\n",
    "if predict[0][0] == 0:\n",
    "    print(test_text,\"is Bad Mean...\")\n",
    "else:\n",
    "    print(test_text,\"is Good Mean!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23-2_MMStudy_Analysis_F-O1JOBGQa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
